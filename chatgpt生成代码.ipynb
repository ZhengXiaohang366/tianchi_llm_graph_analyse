{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98748509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import ujson as json\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"e0a7d609-7a9d-401e-9cd7-53a3819a21f3\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"http://gpt-proxy.jd.com/gateway/azure\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4156a6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_ai_sdk(content):\n",
    "    client = OpenAI(\n",
    "        api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "        base_url=os.environ[\"OPENAI_API_BASE\"],\n",
    "    )\n",
    "    # 此处传入headers中的Authorization 与在client传api_key是一样的\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {os.environ['OPENAI_API_KEY']}\"\n",
    "    }\n",
    "\n",
    "    # 本示例为请求聊天完成接口，如果需要请求别的接口请修改\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        # model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"assistant\"}, \n",
    "                  {\"content\": content, \"role\": \"user\"}],\n",
    "        temperature=0.5,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stream=False,\n",
    "        # 入参时erp改为不必填 但如果输入了erp会校验erp是否真实存在，输入erp与计费相关（不输入则使用申请人erp结算），如果输入erp不对调用会报错哦\n",
    "        # extra_body={\"erp\": \"python\"}\n",
    "        # 请求头\n",
    "        # extra_headers=headers\n",
    "\n",
    "    )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56ab1f74-5aba-4d1f-a6bf-b663d8851ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_ai_sdk(content):\n",
    "    client = OpenAI(\n",
    "        api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "        base_url=os.environ[\"OPENAI_API_BASE\"],\n",
    "    )\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {os.environ['OPENAI_API_KEY']}\"\n",
    "    }\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"assistant\"}, \n",
    "                  {\"content\": content, \"role\": \"user\"}],\n",
    "        temperature=0.5,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stream=False,\n",
    "        # extra_body={\"erp\": \"python\"}\n",
    "        # extra_headers=headers\n",
    "\n",
    "    )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "144e22a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是基于OpenAI的GPT-4模型的一个实例。我的知识截止到2023年10月，并且我无法实时更新。如果你有任何问题或需要帮助，请告诉我！\n"
     ]
    }
   ],
   "source": [
    "content = \"\"\"\n",
    "你是哪个版本的模型？\n",
    "\n",
    "\"\"\"\n",
    "response = open_ai_sdk(content)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b876b2-53ec-4030-a443-b94e7d4f73eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a509a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = f\"\"\"\n",
    "80年代中国为什么会产生恶性通货膨胀？未来中国是否还有可能出现恶性通货膨胀？目前的土地财政是怎样的？房地产销量下滑对未来中国会有什么影响？\n",
    "\"\"\"\n",
    "response = open_ai_sdk(content)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c18dff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1978年对中国而言是一个重要的转折点，这一年标志着中国改革开放的开始，从而结束了此前的高度集中计划经济体制，逐步转向市场经济体制。以下是1978年之后中国历史上的一些重要政治和经济发展：\n",
      "\n",
      "**政治方面：**\n",
      "\n",
      "1. 改革开放：1978年12月，中国共产党在北京召开了十一届三中全会，会议确定了改革开放的基本方针，以邓小平为代表的领导集体开始推行一系列经济和政治改革。\n",
      "\n",
      "2. 领导人变更：中国经历了几代领导人的更替。邓小平虽然没有担任最高领导职务，但在80年代和90年代初期，他是中国实际的最高领导人。之后，江泽民、胡锦涛和习近平分别成为了中国的最高领导人。\n",
      "\n",
      "3. 法制建设：中国政府强调依法治国，加强了法律体系的建设，其中包括修改宪法，制定和修订了一系列法律法规。\n",
      "\n",
      "4. 政治体制改革：尽管政治体制改革的步伐较经济改革慢，但中国也进行了一系列政治体制改革，包括增强人大的作用、推行村民自治等。\n",
      "\n",
      "5. 对外关系：中国逐渐扩大了与外界的接触，加入了世界贸易组织（WTO），并与许多国家建立了外交关系。\n",
      "\n",
      "**经济方面：**\n",
      "\n",
      "1. 农业改革：实行家庭联产承包责任制，结束了人民公社制度，农民获得了更大的土地使用权和经营自由，农业生产效率显著提高。\n",
      "\n",
      "2. 工业改革：国有企业开始实行承包制和股份制改革，引入竞争机制，同时允许和鼓励私营经济的发展。\n",
      "\n",
      "3. 开放政策：设立经济特区和开放沿海城市，吸引外资，引进先进技术和管理经验，推动了经济的快速增长。\n",
      "\n",
      "4. 市场化改革：逐步放开价格管制，建立现代企业制度，发展股票市场和金融市场。\n",
      "\n",
      "5. 经济增长：改革开放以来，中国经济保持了高速增长，成为世界第二大经济体，数亿人口摆脱了贫困。\n",
      "\n",
      "6. 社会变迁：随着经济的发展，中国社会也发生了巨大变化，城镇化进程加快，中产阶级不断壮大，消费模式和生活方式也发生了显著变化。\n",
      "\n",
      "7. 环境与可持续发展：经济快速增长的同时，中国也面临严重的环境污染问题。近年来，中国政府开始重视环境保护和可持续发展，推行绿色发展战略。\n",
      "\n",
      "改革开放40多年来，中国的政治和经济都发生了翻天覆地的变化，经济实力显著增强，国际影响力不断提升。同时，中国也面临着诸如收入分配不均、资源环境压力、社会治理挑战等一系列问题，这些问题的解决是当前和未来中国政治和经济发展的重要任务。\n"
     ]
    }
   ],
   "source": [
    "content = f\"\"\"\n",
    "综述一下中国1978年之后的历史，描述一下政治和经济。\n",
    "\"\"\"\n",
    "response = open_ai_sdk(content)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b68b719",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalServerError",
     "evalue": "<html>\r\n<head><title>504 Gateway Time-out</title></head>\r\n<body bgcolor=\"white\">\r\n<center><h1>504 Gateway Time-out</h1></center>\r\n<hr><center>nginx</center>\r\n</body>\r\n</html>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalServerError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124m如何学习政治学？应该优先了解哪些知识？\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m response \u001b[38;5;241m=\u001b[39m open_ai_sdk(content)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent)\n",
      "Cell \u001b[0;32mIn[2], line 13\u001b[0m, in \u001b[0;36mopen_ai_sdk\u001b[0;34m(content)\u001b[0m\n\u001b[1;32m      7\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuthorization\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBearer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m }\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# 本示例为请求聊天完成接口，如果需要请求别的接口请修改\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     14\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4-1106-preview\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# model=\"gpt-3.5-turbo\",\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m}, \n\u001b[1;32m     17\u001b[0m               {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: content, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m}],\n\u001b[1;32m     18\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m     19\u001b[0m     top_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     20\u001b[0m     frequency_penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     21\u001b[0m     presence_penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     22\u001b[0m     stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# 入参时erp改为不必填 但如果输入了erp会校验erp是否真实存在，输入erp与计费相关（不输入则使用申请人erp结算），如果输入erp不对调用会报错哦\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# extra_body={\"erp\": \"python\"}\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# 请求头\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# extra_headers=headers\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_utils/_utils.py:271\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 271\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/resources/chat/completions.py:648\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    647\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[1;32m    649\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    650\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[1;32m    651\u001b[0m             {\n\u001b[1;32m    652\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[1;32m    653\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m    654\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[1;32m    655\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[1;32m    656\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[1;32m    657\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[1;32m    658\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[1;32m    659\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[1;32m    660\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[1;32m    661\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[1;32m    662\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[1;32m    663\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[1;32m    664\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[1;32m    665\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[1;32m    666\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[1;32m    667\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[1;32m    668\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[1;32m    669\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[1;32m    670\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[1;32m    671\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[1;32m    672\u001b[0m             },\n\u001b[1;32m    673\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[1;32m    674\u001b[0m         ),\n\u001b[1;32m    675\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[1;32m    676\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m    677\u001b[0m         ),\n\u001b[1;32m    678\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[1;32m    679\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    680\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[1;32m    681\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:1167\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1154\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1155\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1162\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1163\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1164\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1165\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1166\u001b[0m     )\n\u001b[0;32m-> 1167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:856\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    848\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    849\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    854\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    855\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 856\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m    857\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m    858\u001b[0m         options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m    859\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    860\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    861\u001b[0m         remaining_retries\u001b[38;5;241m=\u001b[39mremaining_retries,\n\u001b[1;32m    862\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:932\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m    931\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 932\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[1;32m    933\u001b[0m         options,\n\u001b[1;32m    934\u001b[0m         cast_to,\n\u001b[1;32m    935\u001b[0m         retries,\n\u001b[1;32m    936\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    937\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    938\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    939\u001b[0m     )\n\u001b[1;32m    941\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:980\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m    978\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m--> 980\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m    981\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m    982\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m    983\u001b[0m     remaining_retries\u001b[38;5;241m=\u001b[39mremaining,\n\u001b[1;32m    984\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    985\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    986\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:932\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m    931\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 932\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[1;32m    933\u001b[0m         options,\n\u001b[1;32m    934\u001b[0m         cast_to,\n\u001b[1;32m    935\u001b[0m         retries,\n\u001b[1;32m    936\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    937\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    938\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    939\u001b[0m     )\n\u001b[1;32m    941\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:980\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m    978\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m--> 980\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m    981\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m    982\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m    983\u001b[0m     remaining_retries\u001b[38;5;241m=\u001b[39mremaining,\n\u001b[1;32m    984\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    985\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    986\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:947\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    944\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    946\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 947\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    949\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m    950\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m    951\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    954\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    955\u001b[0m )\n",
      "\u001b[0;31mInternalServerError\u001b[0m: <html>\r\n<head><title>504 Gateway Time-out</title></head>\r\n<body bgcolor=\"white\">\r\n<center><h1>504 Gateway Time-out</h1></center>\r\n<hr><center>nginx</center>\r\n</body>\r\n</html>"
     ]
    }
   ],
   "source": [
    "content = f\"\"\"\n",
    "如何学习政治学？应该优先了解哪些知识？\n",
    "\"\"\"\n",
    "response = open_ai_sdk(content)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b8dfee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "截至我所了解的信息，以下是对印度当前的整体、社会、经济和文化的概述，以及对其稳定性和经济前景的简要分析：\n",
      "\n",
      "整体情况：\n",
      "印度是世界上人口第二多的国家，同时也是世界上最大的民主国家。它有着多样的地理特征，从喜马拉雅山脉到印度洋海岸线，以及多种气候类型。由于其历史悠久且多元的文化，印度在世界上拥有独特的地位。\n",
      "\n",
      "社会状况：\n",
      "印度社会极为多元化，拥有多种语言、宗教和文化。社会结构传统上受到种姓制度的影响，尽管现代社会正逐渐改变这一点。印度拥有年轻的人口结构，大量年轻人口为国家的发展提供了潜力。然而，社会不平等、性别差距和贫富差距等问题依然存在。\n",
      "\n",
      "经济状况：\n",
      "印度是一个快速发展的新兴经济体，服务业、制造业和农业是经济的三大支柱。近年来，印度政府推行了多项改革措施，以促进外国直接投资和提高经济效率。尽管如此，印度依然面临着基础设施不足、官僚主义和腐败等挑战。\n",
      "\n",
      "文化状况：\n",
      "印度文化丰富多彩，从古典音乐、舞蹈到现代电影（宝莱坞），都有着深远的影响力。宗教在印度社会中扮演着重要角色，主要宗教包括印度教、伊斯兰教、基督教和锡克教等。\n",
      "\n",
      "稳定性：\n",
      "印度作为一个多元化的国家，不同群体间的紧张关系时有发生。地区性冲突、宗教紧张和社会抗议有时会影响到国家的稳定性。然而，印度的民主体制提供了一个相对稳定的政治环境，允许通过选举和法律程序来解决争议。\n",
      "\n",
      "经济前景：\n",
      "印度的经济前景普遍被认为是积极的。随着其庞大的内需市场、年轻的劳动力和逐步改善的商业环境，印度被预测将在未来几十年内成为世界主要的经济力量之一。不过，为了实现这一预测，印度需要继续在教育、基础设施和治理等方面进行投资和改革。\n",
      "\n",
      "适不适合中国人移民：\n",
      "是否适合移民到印度，这取决于个人的职业目标、生活方式以及对不同文化的适应能力。印度提供了一些商业机会，尤其是在IT、服务业和制造业领域。然而，文化差异、生活条件、语言障碍和社会问题是潜在的挑战。对于有意在印度生活和工作的中国人来说，充分了解当地的法律、文化和经济环境是非常重要的。此外，中印两国在边界和其他战略问题上存在紧张关系，这也可能影响到中国公民在印度的居住和工作经验。\n",
      "\n",
      "综上所述，印度是一个充满机遇和挑战的国家。对于考虑移民的人来说，重要的是做好充分的准备，理解可能面临的困难，并评估个人目标与印度提供的机会之间的匹配程度。\n"
     ]
    }
   ],
   "source": [
    "content = f\"\"\"\n",
    "综述一下印度当前的整体、社会、经济、文化。印度当前是否稳定，未来的经济前景如何，中国人是否适合过去移民。\n",
    "\"\"\"\n",
    "response = open_ai_sdk(content)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5f55b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "如果一个中国人考虑到印度工作，可以通过以下途径寻找工作机会：\n",
      "\n",
      "1. **在线职业平台**：使用国际职业平台如LinkedIn，Indeed，Naukri.com等，可以搜索在印度的工作机会。\n",
      "\n",
      "2. **公司内部调动**：如果在中国工作的公司在印度有分支机构，可以考虑内部调动。\n",
      "\n",
      "3. **招聘顾问和人力资源公司**：联系专门帮助国际专业人士找工作的招聘顾问和人力资源公司，他们可以帮助找到合适的职位。\n",
      "\n",
      "4. **行业交流会和招聘会**：参加与你的专业领域相关的交流会和招聘会，可以增加与潜在雇主的接触机会。\n",
      "\n",
      "5. **教育和研究机构**：如果你在教育或研究领域有经验，可以考虑印度的大学和研究机构。\n",
      "\n",
      "6. **中印商会或经济合作组织**：加入中印商会或经济合作组织，可以帮助你建立商业联系和了解工作机会。\n",
      "\n",
      "以下是一些在印度运营且可能适合国际专业人士的公司类型：\n",
      "\n",
      "- **信息技术和软件服务公司**：如Infosys, Wipro, TCS（塔塔咨询服务公司）等。\n",
      "- **电信公司**：如Bharti Airtel, Reliance Jio等。\n",
      "- **制药和生物技术公司**：如Sun Pharma, Dr. Reddy's Laboratories等。\n",
      "- **汽车制造公司**：如Maruti Suzuki, Tata Motors等。\n",
      "- **能源和基础设施公司**：如Adani Group, Reliance Industries等。\n",
      "- **银行和金融服务公司**：如HDFC Bank, ICICI Bank等。\n",
      "\n",
      "要注意的是，到印度工作通常需要获得工作签证，而这通常需要雇主的支持。此外，对于中国公民来说，由于中印之间的政治关系可能会有额外的签证挑战和限制。因此，在申请工作之前了解当前的签证政策和双边关系是很重要的。\n"
     ]
    }
   ],
   "source": [
    "content = f\"\"\"\n",
    "如果一个中国人考虑到印度工作，可以有哪些途径，有哪些公司会是好的选择\n",
    "\"\"\"\n",
    "response = open_ai_sdk(content)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b0d5ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
